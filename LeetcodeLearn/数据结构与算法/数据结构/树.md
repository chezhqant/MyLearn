1.  树的定义，呃，就是树      
2.  哪几种树：二叉树、二叉查找树、二叉平衡查找树、递归树      
3.  常用概念      
    + 节点的高度=节点到叶子节点的最长路径（边数）     
    + 节点的深度=根节点到这个节点所经历的边的个数     
    + 节点的层数=节点的深度+1       
    + 树的高度=根节点的高度       
    + 叶子节点：没有子节点的节点      
4.  二叉树    
    + 定义：每个节点理论上最多只有两个子节点      
    + 二叉树不要求每个节点一定要有两个子节点，有的时候只有左节点，有的时候只有右节点，有的时候没有节点  
    + 满二叉树：叶子节点全部都在最底层，除了叶子节点之外，每个节点都有两个子节点    
    + 完全二叉树：叶子节点都在最下面两层，最下一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，我觉得这个解释不够清晰
      + 完全二叉树，就是：
        + 满二叉树在最下面一层从左到右删除节点，但是又不全部删掉最后一层。所以先脑补满二叉树，然后从左到右删除     
    + 存储：基于指针或者引用的二叉链式存储法；基于数组的顺序存储法      
      + 为什么会有完全二叉树这种结构？是因为，它使用的存储方式是数组，所以要求完全二叉树的叶子节点要靠左         
    + 遍历    
      + 前序遍历：先打印此节点，再打印左子树，再打印右子树      
      + 中序遍历：先打印左子树，再打印此节点，再打印右子树      
      + 后序遍历：先打印左子树，再打印右子树，再打印此节点      
      [遍历方式](../pictures/遍历方式.PNG)      
        + 前序遍历：      
          ```
          preorder(r) = print r -> preorder(r->left) -> preorder(r->right)

          void pre_order(Node* root)
          {
            print root
            pre_order(root->left);
            pre_order(root->right);
          }
          ```     
        + 中序遍历：      
          ```
          inorder(r) = print r -> inorder(r->left) -> inorder(r->right)

          void in_order(Node* root)
          {
            in_order(root->left);
            print root
            in_order(root->right);
          }
          ```
        + 后序遍历：      
          ```
          postorder(r) = prpostt r -> postorder(r->left) -> postorder(r->right)

          void post_order(Node* root)
          {
            post_order(root->left);
            post_order(root->right);
            print root
          }
          ```
      + 时间复杂度：看上面的图，每个节点最多被遍历两次，所以为O(n)      
5.  二叉查找树      
    + 二叉查找树的最大特点是，支持动态数据集合的快速插入、删除、查找操作      
    + 散列表也是支持这些操作的，并且这些操作比二叉查找树更高效，时间复杂度是O(1)，既然有了这么高效的散列表，为什么还要用二叉查找树？       
    + 二叉查找树要求，在树中的每个节点，其左子树的节点值都要小于这个节点，而右子树的值要大于这个节点的值       
    + 查找操作：先取根节点，如果要等于查找的数据，那就直接返回，如果要查找的数据比根节点值要小，那就在左子树递归查找；如果要查找的数据比根节点值大，那就在右子树中查找：      
      ```
      find(Node root, int data)
      {
        Node p = root;
        while (p != null) {
          if (p->left.data() > data)
            p = p->left;
          else if (p->right.data() < data)
            p = p->right;
          else
            return p;
        }
        return nullptr;
      }
      ```
    + 插入操作：新插入的数据一般都是在叶子节点，所以只需要从根节点开始，一次比较要插入的数据和节点的大小关系。如果要插入的数据比节点的数据大，并且节点的右子树为空，就将数据直接插入到右子节点的位置；如果不为空，就再递归遍历右子树。如果要插入的数据比节点数值小，并且节点的左子树为空，就将数据插入到左子节点的位置，如果不为空，就再递归遍历左子树，查找插入的位置      
      ```
      insert(Node root, int dat)
      {
        if (root == nullptr)
          return;

        Node p = root;
        while (p != nullptr) {
          if (data < p.data) {
            if (p.left == nullptr) {
              p.left = new Node(data);
              return;
            }
            p = p.left;
          } else if (data > p.data) {
            if (p.right == nullptr) {
              p.right = new Node(data);
              return;
            }
            p = p.right;
          }
        }
      }
      ```
    + 删除操作：    
      + 第一种情况：如果要删除的节点没有子节点，我们只需要直接将父节点中指向要删除节点的指针置位nullptr，如下图中的55       
      + 第二种情况：如果要删除的节点只有一个子节点（只有左子节点或者右子节点），我们只需要更新父节点中，指向删除节点的指针，让它指向要删除节点的子节点就可以了，如下图中的33      
      + 第三种情况：如果要删除的节点有两个子节点，我们选哟找到这个节点的右子树中的最小节点，把它替换道要删除的节点上。然后删掉这个最小节点，因为最小节点肯定没有左子节点，如下图中的18        
      ![alt 二叉查找树删除操作](../pictures/二叉查找树删除操作.PNG)        
      ```
      delete(Node root, int data)
      {
        Node p = root; // 指向要删除的节点，初始化指向根节点
        Node pp = nullptr; // 记录的是 p 的父节点

        while (p != nullptr && p.data != data) {
          pp = p;
          if (data > p.data)
            p = p.right;
          else
            p = p.left;
        }

        if (p == nullptr)
          return;

        if (p.left != nullptr && p.right != nullptr) { // 查找右子树的最小节点
          Node min_p = p.right;
          Node min_pp = p; // min_pp 是 min_p 的父节点
          while (min_p.left != nullptr) {
            min_pp = min_p;
            min_p = min_p.left;
          }

          p.data = min_p.data; // 将min_p 的数据替换到p中
          p = min_p;
          pp = min_pp;
        }

        // 删除节点是叶子节点或者仅有一个子节点
        Node child; // p 的子节点
        if (p.left != nullptr)
          child = p.left;
        else if (p.right != nullptr)
          child = p.right;
        else
          child = nullptr;

        if (pp == null)
          root = child; // 删除的是根节点
        else if (pp.left == p)
          pp.left = child;
        else
          pp.right = child;
      }
      ```
      实际上还有一种取巧的方式，单纯的标记要删除的节点，但是并不真正的删除这个节点。这样删除操作就变得简单了     
    + 查找最大节点、最小节点、前驱结点、后继结点      
    + 二叉查找树中序遍历、可以输出有序的数据序列、时间复杂度是O(n)。所以二叉查找树也叫做二叉排序树       
    + 针对有重复数据的数组查找有两种方式：    
      + 二叉查找书中每个节点通过链表和支持动态扩容的数组等结构，可以将值相同的数据存储到一个节点上     
      + 将重复数据放到右子树上      
      + 要查找数据的时候，遇到值相同的节点，我们并不停止查找操作，而是继续在右子树中查找，知道遇到叶子节点才停止。这样才可以将键值等于要查找值的所有节点都找出来    
      + 对于删除操作，我们也需要先查找每个要删除的节点，然后再按照前面讲的删除操作的方法，依次删除     
    + 时间复杂度分析      
      + 想象一下，一个二叉树只有左子树或者右子树，此时就是链表        
      + 对于一棵完全二叉树或者满二叉树。这时候的插入、删除或者查找时间复杂度是多少呢？     
        + 不管是插入、删除或者查找，时间复杂度其实都是和树的高度成正比，也就是O(height)。现在的问题就转向如何求一棵包含n个节点的完全二叉树的高度？树的高度就等于最大层减去一，为了方便计算，我们转换成层来表示。比如说包含n个节点的完全二叉树中，第一层包含一个节点，第二层包含2个人节点，第三层包含4个节点，依次类推，下一层节点的个数是上一层的2倍，第K层包含的节点个数是2^(K-1)。不过对于完全二叉树来说，最后一层的节点个数有点不遵从上面的规律了，它包含的节点个数在1个到2^(L-1)个之间，我们假设最大层数是L，如果我们没一层的节点个数加起来就是总的节点个数n，如果节点的个数是n，那么满足这样一个关系：     
        ```
        n >= 1 + 2 + 4 + 8 + … + 2^(L-2) + 1
        b <= 1 + 2 + 4 + 8 + … + 2^(L-2) + 2^(L-1)
        ```
        借组等比数列的求和公式，L的范围是[log2(n+1), log2n+1]。完全二叉树的层数小于等于log2n+1，完全二叉树的高度小于等于log2n。     
        显然，极度不平衡的二叉查找树，它的查找性能肯定不能满足我们的需求。我们需要构建一种不管删除、插入数据，在任何时候，都能保持任意节点左右子树都比较彭恒的二叉查找树，所以就有了二叉平衡查找树。平衡查找树的高度接近logn，所以插入、删除查找操作的时间复杂度比较稳定，是O(logn)      
  + 所以相对与散列表插入、删除、查找操作的时间复杂度可以做到常量级O(1)，非常搞笑。而二叉查找树在比较平衡的情况下，插入、删除查找操作时间复杂度才是O(logn)，相对散列表好像没有什么优势，那我们为什么还要用二叉查找树呢？      
    + 散列表中的数据时无序存储的。如果要输出有序的数据，需要先进行排序。而对于二叉查找树来说。我们只需要中序遍历，就可以在O(n)的时间复杂度内，输出有序的数据序列     
    + 散列表扩容耗时很多，而且当遇到散列冲突的时候，性能不稳定，尽管二叉查找树的性能不稳定，但是在工程中，我们最常用的二叉平衡查找树的性能非常稳定，时间复杂度稳定在O(logn)     
    + 笼统的说，尽管散列表的查找操作的时间复杂度是常量级的，但是因为哈希冲突的存在，这个常量不一定比logn小，所以实际上查找速度可能不一定比O(logn)。加上哈希函数的耗时，也不一定就比二叉平衡查找树的效率高      
    + 散列表的构造比二叉平衡查找树，散列表装载因子不能太大，特别是给予开放寻址解决冲突的散列表，不然会浪费一定的存储空间         
6.  二叉平衡查找树      
    + 平衡二叉树定义：二叉树中任意一个节点的左右子树的高度相差不大于1，从这个定义来看，完全二叉树、满二叉树其实都是平衡二叉树。但是非完全二叉树也有可能是平衡二叉树     
    + 平衡二叉查找树不仅满足上面平衡二叉树的定义，还满足二叉查找树的特点。最早被发明的平衡二叉树是AVL树，它严格符合平衡二叉查找树的定义，即任何节点的左右子树高度相差不超过1，是一种高度平衡的二叉查找树     
    + 但是很多平衡二叉查找书其实并没有严格符合上面的定义（树中任意一个节点的左右子树的高度相差不能超过1），比如红黑树，它从根节点到各个叶子节点的最长路径，有可能会比最短路径大一倍        
    + 平衡二叉查找树这类数据结构的初衷是，解决普通二叉查找树在频繁的插入、删除等动态更新的情况下，出现时间复杂度退化的问题     
    + 平衡二叉查找树中”平衡“的意思，其实就是让整棵树左右看起来比较对称、比较平衡，不要出现左子树很高，右子树很矮的情况。这样就能让整棵树的高度相对来说低一些，相应的插入、删除、查找等操作的效率高一些      
    + 所以，如果现在设计出一个新的平衡二叉查找树，只要树的高度不比log2n大很多，尽管不符合严格的二叉查找树的定义。但是仍然可以说这是个合格的平衡二叉查找树     
7.  红黑树      
    + 红黑树就不符合严格的平衡二叉查找树的定义      
    + 红黑树中的节点：一类被标记为黑色，一类被标记为红色，一棵红黑树还需满足几个要求：     
      + 根节点是黑色      
      + 每个叶子节点都是黑色的空节点点（NIL），也就是说，叶子节点不存储数据       
      + 任何相邻节点都不能同时共色，也就是说，红色节点是被黑色节点隔开的      
      + 每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色      
    + 第二个要求，叶子节点都是黑色的空节点，稍微有些奇怪，它主要是为了简化红黑树的代码时间而设置的       
    + 二叉查找树很多操作的性能都跟树的高度成正比，一棵极其平衡的二叉树（满二叉树或者完全二叉树）的高度大约是log2n，所以如果要证明红黑树是近似平衡的，我们只需要分析，红黑树的高度是否比较稳定地趋近log2n就好了     
    + 那么将红色节点从红黑树中去掉，那单纯包含黑色节点的红黑树的高度是多少？    
      + 红色节点删除之后，有些节点就没有父节点了，它们会直接拿这些节点的祖父节点作为父节点，所以，之前的二叉树就会编程四叉树。[如图所示](../pictures/二叉树-四叉树.PNG)         
